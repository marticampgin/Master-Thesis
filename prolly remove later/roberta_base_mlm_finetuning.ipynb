{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3PVMnjfQSIjU"
      },
      "outputs": [],
      "source": [
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForMaskedLM,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          TrainingArguments,\n",
        "                          Trainer,\n",
        "                          pipeline)\n",
        "\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSyEAkRQTfNK"
      },
      "outputs": [],
      "source": [
        "# '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'\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV5H82o3TnSm"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('marticampgin/ietf_texts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oU9hq8o5Tykq"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JItxSvTT6Eo"
      },
      "outputs": [],
      "source": [
        "mask_filler_no_ft = pipeline('fill-mask', 'roberta-base')\n",
        "\n",
        "texts = ['i <mask> adoption of this draft',\n",
        "         'develop <mask> protocols',\n",
        "         'dear working <mask>',\n",
        "         'i have updated the <mask>']\n",
        "\n",
        "mask_filler_no_ft(texts, top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4J2f6W7U3Tr",
        "outputId": "3dba9a96-1cd3-4f91-cf22-020e1747e39b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 51065. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(51065, 768)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Adding domain specific tokens to the tokenizer, modifying models token embedding matrix\n",
        "_ = tokenizer.add_tokens(top_800_tokens)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1orZT9W9U7Mk",
        "outputId": "4c780a73-b526-4d82-aa9b-c0d76e061c79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'the usage of the term \"path\" is actually misleading, at least i see that i am misusing it. we can only consider pairs of local ip address and remote ip address, not all the path. when related to section [link], i think that it should apply to the source-destination pair rather than the destination only, and this is because sctp cannot assume that reaching a destination has the same characteristics from all the sources at a certain time. when doing a \"path\" probing, part of the values of section [link] can be already available, for instance srtt, rto, pmtu, state. about source based routing, currently sctp is already used in scenarios involving security gateways so that a set of destination addresses can only be reached from a subset of source addresses, this is not prohibited from rfc4960.'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LTJwfnNbVZah"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer([\" \".join(x) for x in list(examples[\"text\"])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l24CuIx2WEwU"
      },
      "outputs": [],
      "source": [
        "tokenized_dset = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldC-SJsxXFEp"
      },
      "outputs": [],
      "source": [
        "tokenized_dset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kWarCcP7XWit"
      },
      "outputs": [],
      "source": [
        "block_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9BY28HyiXYaQ"
      },
      "outputs": [],
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oggH2FyKXfR4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aecbbc9c17174270b44e087edb3d9d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28005 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a088895390b446fb887e8da53f401de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3112 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lm_dataset = tokenized_dset.map(group_texts, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mF2cVAq-X7Bx"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "5YWq0uwyYHkI",
        "outputId": "f79c9666-45cc-4edd-eeac-90f9477a88fb"
      },
      "outputs": [],
      "source": [
        "seed = 77\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"roberta_ietf_finetuned\",\n",
        "    evaluation_strategy='steps',\n",
        "    logging_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    save_total_limit=5,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        "    seed=seed,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_dataset[\"train\"],\n",
        "    eval_dataset=lm_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c2232c18aa847fca4e6bfe7fe523e51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "058a80aae8944170aa358f9fe4e8ebff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3848956d73144bcb46928ec19a86d9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/marticampgin/roberta_ietf_finetuned/tree/main/'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/marticampgin/roberta_ietf_finetuned/commit/bee736415884cf78d977348ca8b10dbe97332105', commit_message='Upload tokenizer', commit_description='', oid='bee736415884cf78d977348ca8b10dbe97332105', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.push_to_hub('marticampgin/roberta_ietf_finetuned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_filler_ft = pipeline(\"fill-mask\", \"marticampgin/roberta_ietf_finetuned\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
