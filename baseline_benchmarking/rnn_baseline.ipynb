{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "import pandas as pd \n",
    "import random \n",
    "import warnings\n",
    "import os \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data_path = \"./data\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_path, \"train_data.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"test_data.csv\"))\n",
    "\n",
    "train_texts, train_labels = train_df.text.tolist(), train_df.label.tolist()\n",
    "test_texts, test_labels = test_df.text.tolist(), test_df.label.tolist()\n",
    "\n",
    "# Simple whitespace split\n",
    "tok_train_texts = [[w for w in txt.split() if w != \"\"] for txt in train_texts]\n",
    "tok_test_texts = [[w for w in txt.split() if w != \"\"] for txt in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courtesy for the code to https://github.com/bentrevett/pytorch-sentiment-analysis?tab=readme-ov-file\n",
    "\n",
    "# Hyperparameters for dataset\n",
    "max_length = 200\n",
    "min_freq = 5\n",
    "batch_size = 16\n",
    "\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "mapping = {0: 0, 1: 1, -1: 2}\n",
    "\n",
    "def tokenize(example, max_length):\n",
    "    # Simple whitespace-tokenization\n",
    "    tokens = [word for word in example['text'].split() if word != \"\"][:max_length]\n",
    "    length = len(tokens)\n",
    "    return {\"tokens\": tokens, \"length\": length}\n",
    "\n",
    "def numericalize_example(example, vocab):\n",
    "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
    "    return {\"ids\": ids}\n",
    "\n",
    "# Transform datasets\n",
    "train_df = pd.DataFrame({\"text\": train_texts, \"label\": train_labels}) \n",
    "test_df = pd.DataFrame({\"text\": test_texts, \"label\": test_labels}) \n",
    "\n",
    "# Re-map labels to avoid errors\n",
    "train_df['label'] = train_df['label'].map(mapping)\n",
    "test_df['label'] = test_df['label'].map(mapping)\n",
    "\n",
    "# Obtain HF datasets\n",
    "train_ds = datasets.Dataset.from_pandas(train_df)\n",
    "test_ds = datasets.Dataset.from_dict(test_df)\n",
    "\n",
    "# Map tokenization\n",
    "train_ds = train_ds.map(\n",
    "        tokenize, fn_kwargs={\"max_length\": max_length}\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "        tokenize, fn_kwargs={\"max_length\": max_length}\n",
    ")\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_ds[\"tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens\n",
    ")\n",
    "\n",
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "vocab.set_default_index(unk_index)\n",
    "\n",
    "train_ds = train_ds.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "test_ds = test_ds.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "\n",
    "train_data = train_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
    "test_data = test_ds.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Craete nested function to avoid writing a class\n",
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = []\n",
    "        batch_length = []\n",
    "        batch_label = []\n",
    "\n",
    "        for sample in batch:\n",
    "            batch_ids.append(sample[\"ids\"])\n",
    "            batch_length.append(sample[\"length\"])\n",
    "            batch_label.append(sample['label'])\n",
    "        \n",
    "        # Padding to the size of largest sequence in the batch\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_label = torch.stack(batch_label)\n",
    "        batch = {\"ids\": batch_ids, \"length\": batch_length, \"label\": batch_label}\n",
    "        return batch\n",
    "    return collate_fn\n",
    "\n",
    "\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_loader       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, n_layers, bidir, dropout, pad_index,):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_index)\n",
    "        # Straightforward implementation of an RNN \n",
    "        self.rnn = nn.RNN(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            bidirectional=bidir,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidir else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, ids, length):\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        \n",
    "        # Padded/packed sequences for better efficiency\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, hidden = self.rnn(packed_embedded)  \n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "            \n",
    "        prediction = self.fc(hidden)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_scores(prediction, golden_label):\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    report = classification_report(golden_label.cpu(), predicted_classes.cpu(), output_dict=True)\n",
    "    macro_f1 = report['macro avg']['f1-score']\n",
    "    micro_f1 = report['weighted avg']['f1-score']\n",
    "    return macro_f1, micro_f1 \n",
    "\n",
    "\n",
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_macro_f1s = []\n",
    "    epoch_micro_f1s = []\n",
    "    \n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        length = batch[\"length\"]\n",
    "        label = batch[\"label\"].to(device)\n",
    "\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        macro_f1, micro_f1 = get_f1_scores(prediction, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_macro_f1s.append(macro_f1)\n",
    "        epoch_micro_f1s.append(micro_f1)\n",
    "        \n",
    "    return np.mean(epoch_losses), np.mean(epoch_macro_f1s), np.mean(epoch_micro_f1s)\n",
    "\n",
    "\n",
    "def evaluate_full(dataloader, model, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    golden_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            length = batch[\"length\"]\n",
    "            label = batch[\"label\"].to(device) \n",
    "\n",
    "            prediction = model(ids, length)\n",
    "            predicted_classes = prediction.argmax(dim=-1)\n",
    "            \n",
    "            predictions.extend(predicted_classes.tolist())\n",
    "            golden_labels.extend(label.tolist())\n",
    "\n",
    "    print(classification_report(golden_labels, predictions))\n",
    "\n",
    "\n",
    "def evaluate_batched_f1_scores(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_macro_f1s = []\n",
    "    epoch_micro_f1s = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            length = batch[\"length\"]\n",
    "            label = batch[\"label\"].to(device)\n",
    "\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            \n",
    "            macro_f1, micro_f1 = get_f1_scores(prediction.cpu(), label.cpu())\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_macro_f1s.append(macro_f1)\n",
    "            epoch_micro_f1s.append(micro_f1)\n",
    "    return np.mean(epoch_losses), np.mean(epoch_macro_f1s), np.mean(epoch_micro_f1s)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=8):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 421,335 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Model/train hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "embed_dim = 300\n",
    "hidden_dim = 256\n",
    "output_dim = len(train_data.unique(\"label\"))\n",
    "\n",
    "n_layers = 1  # rnn layers\n",
    "bidir = True  # bidirectional\n",
    "dropout = 0.3\n",
    "lr = 5e-4\n",
    "\n",
    "model = RNN(vocab_size, embed_dim, hidden_dim, output_dim, n_layers, bidir, dropout, pad_index)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vectors = torchtext.vocab.GloVe(name=\"840B\", dim=300) # GloVE embeddings\n",
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 57.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 107.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Train loss: 1.068, Train macro f1: 0.309, Train micro f1: 0.361\n",
      "Test_loss: 1.016, Test macro f1: 0.501, Test micro f1: 0.532\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 53.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 132.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.885, Train macro f1: 0.556, Train micro f1: 0.614\n",
      "Test_loss: 0.980, Test macro f1: 0.443, Test micro f1: 0.479\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 53.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 128.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.755, Train macro f1: 0.710, Train micro f1: 0.723\n",
      "Test_loss: 0.951, Test macro f1: 0.414, Test micro f1: 0.443\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 58.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 127.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Train loss: 0.580, Train macro f1: 0.811, Train micro f1: 0.826\n",
      "Test_loss: 0.874, Test macro f1: 0.506, Test micro f1: 0.574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "best_macro_f1 = 0.0\n",
    "best_micro_f1 = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train_loss, train_macro_f1, train_micro_f1 = train(\n",
    "        train_data_loader, model, criterion, optimizer, device\n",
    "    )\n",
    "\n",
    "    test_loss, test_macro_f1, test_micro_f1 = evaluate_batched_f1_scores(test_data_loader, model, criterion, device)\n",
    "\n",
    "    # The model with best test metrics will be saved in current directory as \"rnn.pt\"\n",
    "    if test_macro_f1 > best_macro_f1 and test_micro_f1 > best_micro_f1:\n",
    "        best_macro_f1 = test_macro_f1\n",
    "        best_micro_f1 = test_micro_f1\n",
    "        torch.save(model.state_dict(), \"rnn.pt\")\n",
    "        print(\"Saving model...\")\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.3f}, Train macro f1: {train_macro_f1:.3f}, Train micro f1: {train_micro_f1:.3f}\")\n",
    "    print(f\"Test_loss: {test_loss:.3f}, Test macro f1: {test_macro_f1:.3f}, Test micro f1: {test_micro_f1:.3f}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.69        20\n",
      "           1       0.75      0.63      0.69        19\n",
      "           2       0.57      0.31      0.40        13\n",
      "\n",
      "    accuracy                           0.63        52\n",
      "   macro avg       0.64      0.60      0.59        52\n",
      "weighted avg       0.64      0.63      0.62        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set \n",
    "model = RNN(vocab_size, embed_dim, hidden_dim, output_dim, n_layers, bidir, dropout, pad_index).to(device)\n",
    "model.load_state_dict(torch.load(\"rnn.pt\"))\n",
    "\n",
    "evaluate_full(test_data_loader, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
