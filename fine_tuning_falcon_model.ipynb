{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1I8PP--pJv"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq bitsandbytes==0.39.0\n",
        "!pip install -qqq torch==2.0.1\n",
        "!pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc\n",
        "!pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f\n",
        "!pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71\n",
        "!pip install -qqq datasets==2.12.0\n",
        "!pip install -qqq loralib==0.1.1\n",
        "!pip install -qqq einops==0.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JTpOpONABXC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from datasets import Dataset\n",
        "from pprint import pprint\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxDOewIzAIQs"
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVeAl4kAWph"
      },
      "outputs": [],
      "source": [
        "# This model is specifically tailored to run in low-ram enviroments (such as this, colab)\n",
        "CHECKPOINT = 'vilsonrodrigues/falcon-7b-instruct-sharded'\n",
        "\n",
        "# Bits and bites config to quantize the model (brainfloat16 -> normalized float 4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    CHECKPOINT,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SN0JExr-Cskn"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "  \"\"\"\n",
        "  Prints the number of trainable parameters in the model.\n",
        "  \"\"\"\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "  for _, param in model.named_parameters():\n",
        "    all_param += param.numel()\n",
        "    if param.requires_grad:\n",
        "      trainable_params += param.numel()\n",
        "  print(\n",
        "      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "loA39qYvDLz-"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNuN0-Y8DP5v",
        "outputId": "a589ab6e-39b7-4347-cf51-fe6a2356c043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4718592 || all params: 3613463424 || trainables%: 0.13058363808693696\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,  # can be raised (to e.g. 64)\n",
        "    lora_alpha=32,  # can be lowered (to e.g. 16)\n",
        "    target_modules=[\"query_key_value\"],  # can include more layers\n",
        "    lora_dropout=0.05,  # can be raised (to e.g. 0.1)\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)  # by utilizing low rank adaptation, we only train 13% of all avaliable, trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bB-WhoSfGBbj"
      },
      "outputs": [],
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 3  # the longest seq. that the model can generate should be _-1, which is max. 3 chars\n",
        "generation_config.temperature = 0  # we need low temperature, to ensure that model the highest prob. token\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"\"\"You are a sentiment analysis model. Your task is to evaluate the sentiment\n",
        "of the given text and output a sentiment score between -1 and 1, where -1 signifies\n",
        "a negative sentiment, 0 indicates neutral, and 1 represents positive sentiment.\"\"\"\n",
        "\n",
        "\n",
        "prompt2 = \"\"\"Anlyze the sentiment of the given text and output a sentiment score\n",
        "between -1 and 1, where -1 signifies a negative sentiment, 0 indicates neutral,\n",
        "and 1 represents positive sentiment.\"\"\"\n"
      ],
      "metadata": {
        "id": "RWms5h36BBKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EcKcwI5GHgHU"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(data_point):\n",
        "  return f\"\"\"Anlyze the sentiment of the given text and output a sentiment score\n",
        "between -1 and 1, where -1 signifies a negative sentiment, 0 indicates neutral,\n",
        "and 1 represents positive sentiment.\n",
        "\n",
        "<text>: {data_point['User']}\n",
        "<sentiment>: {data_point['Prompt']}\n",
        "\"\"\".strip()\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "  full_prompt = generate_prompt(data_point)\n",
        "  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
        "  return tokenized_full_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ssvnx7QBIUIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2e5d84cdbd904c11af524ab2dea8efbe",
            "c0e2aba3f43a44639d551845c27ce676",
            "8f1c5f6cbe704721a2e89218a8710eb2",
            "4686e4f72ac5497482c238ab211817d3",
            "b88d69f1bd314032a06ceaeed6971283",
            "1aabc0ffaaaf41da89aa6fdaf1348c09",
            "311b552d7c9f46aeb3a80d2cbb942908",
            "c9880b63e9fb45ada5ee56997113dba6",
            "91a179d6a03a4631bfd4886608665381",
            "5233ed5d858741e190ffe7bf4a1a3d38",
            "7dd56774a2d8442fb28eab0d2de6eacf"
          ]
        },
        "outputId": "5c671feb-63fb-494b-de8e-1df428e654fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e5d84cdbd904c11af524ab2dea8efbe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Our custom dataset\n",
        "train_data = pd.read_csv(\"train_data.csv\")\n",
        "train_data.rename(columns={\"text\": \"User\", \"label\": \"Prompt\"}, inplace=True)\n",
        "dataset = Dataset.from_pandas(train_data)\n",
        "dataset = dataset.shuffle().map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL-n5mqsI9hS"
      },
      "source": [
        "## Finetuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PVQJvqLI7x8"
      },
      "outputs": [],
      "source": [
        "training_args = transformers.TrainingArguments(\n",
        "      per_device_train_batch_size=1,\n",
        "      gradient_accumulation_steps=4,\n",
        "      num_train_epochs=1,\n",
        "      learning_rate=2e-4,\n",
        "      fp16=True,\n",
        "      save_total_limit=3,\n",
        "      logging_steps=1,\n",
        "      output_dir=\"experiments\",\n",
        "      optim=\"paged_adamw_8bit\",\n",
        "      lr_scheduler_type=\"cosine\",\n",
        "      warmup_ratio=0.05,\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    args=training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PF3-hoNfMtbb"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"trained-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RodHdWeMM5YG"
      },
      "outputs": [],
      "source": [
        "config = PeftConfig.from_pretrained(\"trained-model\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = PeftModel.from_pretrained(model, \"trained-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ni9pqVg3NpUL"
      },
      "outputs": [],
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 3\n",
        "generation_config.temperature = 0\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WipYV092Nqlc",
        "outputId": "dbe19ea3-a5e0-46dd-8139-9c750f756663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anlyze the sentiment of the given text and output a sentiment score \n",
            "between -1 and 1, where -1 signifies a negative sentiment, 0 indicates neutral, \n",
            "and 1 represents positive sentiment.\n",
            "\n",
            "<text>: the arp extension discussed in this document is a good addition to the label-distribution toolkit and can potentially be the simplest option available for certain deployments. i support wg adoption.\n",
            "<sentiment>: 0\n",
            "\n",
            "CPU times: user 1.21 s, sys: 0 ns, total: 1.21 s\n",
            "Wall time: 2.05 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "prompt = \"\"\"Anlyze the sentiment of the given text and output a sentiment score\n",
        "between -1 and 1, where -1 signifies a negative sentiment, 0 indicates neutral,\n",
        "and 1 represents positive sentiment.\n",
        "\n",
        "<text>: the arp extension discussed in this document is a good addition to the label-distribution toolkit and can potentially be the simplest option available for certain deployments. i support wg adoption.\n",
        "<sentiment>:\n",
        "\"\"\".strip()\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "with torch.inference_mode():\n",
        "  outputs = model.generate(\n",
        "      input_ids = encoding.input_ids,\n",
        "      attention_mask = encoding.attention_mask,\n",
        "      generation_config = generation_config\n",
        "  )\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e5d84cdbd904c11af524ab2dea8efbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0e2aba3f43a44639d551845c27ce676",
              "IPY_MODEL_8f1c5f6cbe704721a2e89218a8710eb2",
              "IPY_MODEL_4686e4f72ac5497482c238ab211817d3"
            ],
            "layout": "IPY_MODEL_b88d69f1bd314032a06ceaeed6971283"
          }
        },
        "c0e2aba3f43a44639d551845c27ce676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aabc0ffaaaf41da89aa6fdaf1348c09",
            "placeholder": "​",
            "style": "IPY_MODEL_311b552d7c9f46aeb3a80d2cbb942908",
            "value": "Map:  84%"
          }
        },
        "8f1c5f6cbe704721a2e89218a8710eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9880b63e9fb45ada5ee56997113dba6",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91a179d6a03a4631bfd4886608665381",
            "value": 203
          }
        },
        "4686e4f72ac5497482c238ab211817d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5233ed5d858741e190ffe7bf4a1a3d38",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd56774a2d8442fb28eab0d2de6eacf",
            "value": " 170/203 [00:00&lt;00:00, 526.82 examples/s]"
          }
        },
        "b88d69f1bd314032a06ceaeed6971283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1aabc0ffaaaf41da89aa6fdaf1348c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311b552d7c9f46aeb3a80d2cbb942908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9880b63e9fb45ada5ee56997113dba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a179d6a03a4631bfd4886608665381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5233ed5d858741e190ffe7bf4a1a3d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd56774a2d8442fb28eab0d2de6eacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}