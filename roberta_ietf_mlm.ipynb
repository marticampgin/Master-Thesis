{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ietf_wg_mb_extractor import IETF_WG_MB_Extractor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from explore_data import DataExplorer\n",
    "from prepare_data import DataPreparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped active WG names\n",
      "------------------------------------\n",
      "Successfully extracted names of active WGs existing in files\n",
      "------------------------------------------------------------\n",
      "Successfully converted and concatenated all .csv files into one dataframe\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "archive_path = 'email-archives/'\n",
    "\n",
    "extractor = IETF_WG_MB_Extractor(archive_path)\n",
    "extractor.combine_wg_files(ratio=None)\n",
    "# Can remove the below getter method, and just return the big df after with combine_wg_files()\n",
    "active_wg_dataframe = extractor.get_combined_wg_dataframes()\n",
    "data_preparator = DataPreparator(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataframe shape: (532860, 8)\n",
      "-----------------------------------------\n",
      "Dataframe shape after cleaning rows: (46956, 9)\n",
      "\n",
      "------PROCESSING------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46956/46956 [01:04<00:00, 724.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepocessing time: 64.84 s.\n",
      "\n",
      "Number of mails removed: 13108\n",
      "---------------------------------------\n",
      "Encrypted messages: 3392\n",
      "Ill from-formated messages: 208\n",
      "Announc. messages: 4813\n",
      "Unknown endcoding messages: 62\n",
      "Empty messages post-processing: 4083\n",
      "Diff. language: 463\n",
      "Diverse other noise: 87\n"
     ]
    }
   ],
   "source": [
    "clean_wg_dataframe = data_preparator.emails_df_cleaning(active_wg_dataframe)\n",
    "processed_bodies = data_preparator.preprocess_bodies()\n",
    "text_coll_combined = data_preparator.wg_combined_bodies_to_dict(processed_bodies)\n",
    "text_coll_default = data_preparator.wg_bodies_to_dict(processed_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested num. of samples: 31749\n",
      "Actual num. of samples (due to post duplicate-removal): 31169\n"
     ]
    }
   ],
   "source": [
    "train_bodies = data_preparator.prepare_data_for_model(text_coll_default, seed=77, percent_of_data=1)\n",
    "\n",
    "# Noise that could not have been removed, (NEED THIS TO COUNT TOWARDS OVERALL NUM OF SAMPLES STATISTIC) \n",
    "train_bodies = [body for body in train_bodies if 'count bytes who' not in body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Potential models: roberta-base, bert-base-uncased\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab = tokenizer.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import contractions\n",
    "\n",
    "# WE SHOULD ADD THIS OR SOIME KIND OF OTHER, BETTER THAN REGULAR SPLIT TOKENIZER TO WHERE WE DO STATISTICS AS WELL\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "additional_unwanted_tokens = [\"''\", \"``\", \"'s\", \"”\", \"“\", \"b\", \"c\", \"x\" \"r\"]\n",
    "for ch in additional_unwanted_tokens:\n",
    "    punctuation += ch\n",
    "\n",
    "all_tokens = []\n",
    "\n",
    "for body in train_bodies:\n",
    "    body = contractions.fix(body)\n",
    "    tokenized_body = word_tokenize(body)\n",
    "    for token in tokenized_body:\n",
    "        if token not in punctuation and token not in eng_stopwords and token not in model_vocab:\n",
    "            includes_digits = any(chr.isdigit() for chr in token)\n",
    "            if not includes_digits:\n",
    "                all_tokens.append(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 800 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After 1000k words, it kinda flattens out \n",
    "cnt = Counter(all_tokens)\n",
    "counts = [count for _, count in cnt.most_common(800)]\n",
    "\n",
    "plt.ylim([0, 6000])\n",
    "plt.bar(range(len(counts)), counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see for what percentange of all words does each nth most common word account\n",
    "total_amount_of_words = len(all_tokens)\n",
    "\n",
    "accumulated_count = 0\n",
    "for i, word_count in enumerate(cnt.most_common()):\n",
    "    accumulated_count += word_count[1]\n",
    "    print(f'{i} most common word(s) account for {round((accumulated_count / total_amount_of_words)*100, 2)}% of data')\n",
    "    \n",
    "# The top 800 words account for rougly 51% of all tokens in our custom data. It is also roughly equal to 1.6% of existing roberta tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_800_tokens = [token for token, _ in cnt.most_common(800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 51065. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(51065, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding domain specific tokens to the tokenizer, modifying models token embedding matrix\n",
    "_ = tokenizer.add_tokens(top_800_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "data = [{'text': list(text)} for text in train_bodies]\n",
    "dataset = Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"as a reminder, we will have an interim on tuesday oct 5th at 1500 utc. the materials will be available at [1] and the webex link is at [2]. i suggest the following familiar-looking draft agenda: - administrivia and agenda bash (chairs, 5 mins) - interop report (marco tiloca, 5 mins) - edhoc open issues (gran selander & john mattsson, nn mins) - aob we are looking for a notetaker. please volunteer by sending an email to the chairs at lake-chairs@[link] if you have any suggested agenda changes please feel free to respond to this mail. if you're mentioned above as a presenter please send any slideware to the chairs or let us know if there's any issue with that.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed17b618194f558484f805f7b042b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8788c7bea24495b77de25e686175bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f8fc19a305455c8ac294950660d76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lm_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtokenized_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\dataset_dict.py:855\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 855\u001b[0m     \u001b[43m{\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\dataset_dict.py:856\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    855\u001b[0m     {\n\u001b[1;32m--> 856\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    876\u001b[0m     }\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\arrow_dataset.py:3466\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3462\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3463\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3464\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3466\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3470\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3472\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3475\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3347\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3348\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3349\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m, in \u001b[0;36mgroup_texts\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_texts\u001b[39m(examples):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Concatenate all texts.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     concatenated_examples \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      4\u001b[0m     total_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(concatenated_examples[\u001b[38;5;28mlist\u001b[39m(examples\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# customize this part to your needs.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_texts\u001b[39m(examples):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Concatenate all texts.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     concatenated_examples \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m examples\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m      4\u001b[0m     total_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(concatenated_examples[\u001b[38;5;28mlist\u001b[39m(examples\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# customize this part to your needs.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "lm_dataset = tokenized_datasets.map(group_texts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fa0460ebfe4ac0b25b2aa1779fcde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2563, 'learning_rate': 1.914529914529915e-05, 'epoch': 0.13}\n",
      "{'loss': 2.9905, 'learning_rate': 1.829059829059829e-05, 'epoch': 0.26}\n",
      "{'loss': 2.8322, 'learning_rate': 1.7435897435897438e-05, 'epoch': 0.38}\n",
      "{'loss': 2.7553, 'learning_rate': 1.6581196581196585e-05, 'epoch': 0.51}\n",
      "{'loss': 2.6849, 'learning_rate': 1.5726495726495726e-05, 'epoch': 0.64}\n",
      "{'loss': 2.6653, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.77}\n",
      "{'loss': 2.621, 'learning_rate': 1.4017094017094018e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f38d58dcbac4c5db151966171573121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.470242738723755, 'eval_runtime': 17.8041, 'eval_samples_per_second': 315.433, 'eval_steps_per_second': 39.429, 'epoch': 1.0}\n",
      "{'loss': 2.5851, 'learning_rate': 1.3162393162393164e-05, 'epoch': 1.03}\n",
      "{'loss': 2.522, 'learning_rate': 1.230769230769231e-05, 'epoch': 1.15}\n",
      "{'loss': 2.4948, 'learning_rate': 1.1452991452991454e-05, 'epoch': 1.28}\n",
      "{'loss': 2.4903, 'learning_rate': 1.05982905982906e-05, 'epoch': 1.41}\n",
      "{'loss': 2.4515, 'learning_rate': 9.743589743589744e-06, 'epoch': 1.54}\n",
      "{'loss': 2.4597, 'learning_rate': 8.888888888888888e-06, 'epoch': 1.67}\n",
      "{'loss': 2.4199, 'learning_rate': 8.034188034188036e-06, 'epoch': 1.79}\n",
      "{'loss': 2.399, 'learning_rate': 7.17948717948718e-06, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f076c34e83a54a8a99ee4633de998b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3092458248138428, 'eval_runtime': 17.8421, 'eval_samples_per_second': 314.761, 'eval_steps_per_second': 39.345, 'epoch': 2.0}\n",
      "{'loss': 2.3887, 'learning_rate': 6.324786324786325e-06, 'epoch': 2.05}\n",
      "{'loss': 2.3843, 'learning_rate': 5.470085470085471e-06, 'epoch': 2.18}\n",
      "{'loss': 2.3381, 'learning_rate': 4.615384615384616e-06, 'epoch': 2.31}\n",
      "{'loss': 2.3437, 'learning_rate': 3.760683760683761e-06, 'epoch': 2.44}\n",
      "{'loss': 2.3042, 'learning_rate': 2.9059829059829063e-06, 'epoch': 2.56}\n",
      "{'loss': 2.3095, 'learning_rate': 2.0512820512820513e-06, 'epoch': 2.69}\n",
      "{'loss': 2.3086, 'learning_rate': 1.1965811965811968e-06, 'epoch': 2.82}\n",
      "{'loss': 2.3087, 'learning_rate': 3.4188034188034194e-07, 'epoch': 2.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417e6549ac684853b1f5c4b19aa38690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2326507568359375, 'eval_runtime': 17.6738, 'eval_samples_per_second': 317.759, 'eval_steps_per_second': 39.72, 'epoch': 3.0}\n",
      "{'train_runtime': 1237.8985, 'train_samples_per_second': 75.61, 'train_steps_per_second': 9.452, 'train_loss': 2.530918983394264, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11700, training_loss=2.530918983394264, metrics={'train_runtime': 1237.8985, 'train_samples_per_second': 75.61, 'train_steps_per_second': 9.452, 'train_loss': 2.530918983394264, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"roberta_ietf_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
