{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "47zM2nKJChBK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForSeq2SeqLM,\n",
        "                          Seq2SeqTrainingArguments,\n",
        "                          Seq2SeqTrainer,\n",
        "                          DataCollatorForSeq2Seq)\n",
        "\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from roberta_type_models_testing import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def generate_sample(text):\n",
        "  return f\"\"\"Perform Sentiment classification task.\n",
        "Given the text assign a sentiment label from ['negative', 'positive', 'neutral'].\n",
        "Return label only without any other text.\n",
        "\n",
        "<text>: {text}\n",
        "<sentiment>: \"\"\".strip()\n",
        "\n",
        "def run_on_test(test_dataset, model, str2int):\n",
        "    golden_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    test_texts, test_labels = test_dataset['text'], test_dataset['label']\n",
        "    inputs = [generate_sample(text) for text in test_texts]\n",
        "\n",
        "    # Running inference on 1 sample at a time to avoid OOM issue\n",
        "    for i, input in enumerate(tqdm(inputs)):\n",
        "      input = tokenizer(input, return_tensors='pt').to('cuda')\n",
        "      output = model.generate(**input)\n",
        "\n",
        "      golden_labels.append(str2int[test_labels[i]])\n",
        "      predicted_labels.append(str2int[tokenizer.decode(output[0], skip_special_tokens=True)])\n",
        "\n",
        "    return golden_labels, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef29f5e12aed4c3a8846840207140096",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5218, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc3ec75ac43f494587348b4e08b66f2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.28298136591911316, 'eval_runtime': 0.8405, 'eval_samples_per_second': 93.992, 'eval_steps_per_second': 11.898, 'epoch': 1.0}\n",
            "{'loss': 0.4506, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3c9686568214af8bc3f097dee48a27b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.27833157777786255, 'eval_runtime': 0.857, 'eval_samples_per_second': 92.182, 'eval_steps_per_second': 11.669, 'epoch': 2.0}\n",
            "{'loss': 0.4708, 'learning_rate': 0.0, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efcf2f58c58b4fb495dfa3a62bd00d26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.27727729082107544, 'eval_runtime': 0.8447, 'eval_samples_per_second': 93.52, 'eval_steps_per_second': 11.838, 'epoch': 3.0}\n",
            "{'train_runtime': 23.4517, 'train_samples_per_second': 1.535, 'train_steps_per_second': 0.256, 'train_loss': 0.4810561140378316, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/79 [00:00<?, ?it/s]c:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 79/79 [00:02<00:00, 32.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7241    0.9130    0.8077        23\n",
            "           0     0.7083    0.5862    0.6415        29\n",
            "           1     0.8462    0.8148    0.8302        27\n",
            "\n",
            "    accuracy                         0.7595        79\n",
            "   macro avg     0.7595    0.7714    0.7598        79\n",
            "weighted avg     0.7600    0.7595    0.7544        79\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be6e1aabe14c45c5bed7dca7e68d1d40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3884, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fced1f84ba7149f89525fc31e9f09a55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.27944520115852356, 'eval_runtime': 0.837, 'eval_samples_per_second': 94.38, 'eval_steps_per_second': 11.947, 'epoch': 1.0}\n",
            "{'loss': 0.5838, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4c320e9c48548a8b87b3238e3bce75d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2760010063648224, 'eval_runtime': 0.8348, 'eval_samples_per_second': 94.635, 'eval_steps_per_second': 11.979, 'epoch': 2.0}\n",
            "{'loss': 0.4694, 'learning_rate': 0.0, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b6266e3d50b41868611c9f9dea885e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2738625407218933, 'eval_runtime': 0.8376, 'eval_samples_per_second': 94.322, 'eval_steps_per_second': 11.939, 'epoch': 3.0}\n",
            "{'train_runtime': 12.7932, 'train_samples_per_second': 2.814, 'train_steps_per_second': 0.469, 'train_loss': 0.480550080537796, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/79 [00:00<?, ?it/s]c:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:02<00:00, 32.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7600    0.8261    0.7917        23\n",
            "           0     0.6667    0.7586    0.7097        29\n",
            "           1     0.9524    0.7407    0.8333        27\n",
            "\n",
            "    accuracy                         0.7722        79\n",
            "   macro avg     0.7930    0.7751    0.7782        79\n",
            "weighted avg     0.7915    0.7722    0.7758        79\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3abb790357d74f4191681b9f792b7c9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3748, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2233b0d10f884b2b86500e9743345785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.31317058205604553, 'eval_runtime': 0.8385, 'eval_samples_per_second': 94.215, 'eval_steps_per_second': 11.926, 'epoch': 1.0}\n",
            "{'loss': 0.4719, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "166409addd0b4281b9b7e6cc0b77c33a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2941657602787018, 'eval_runtime': 0.8391, 'eval_samples_per_second': 94.151, 'eval_steps_per_second': 11.918, 'epoch': 2.0}\n",
            "{'loss': 0.4127, 'learning_rate': 0.0, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ce3c10b177f4d549bd3b41bd725b262",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.28749600052833557, 'eval_runtime': 1.0498, 'eval_samples_per_second': 75.254, 'eval_steps_per_second': 9.526, 'epoch': 3.0}\n",
            "{'train_runtime': 17.3709, 'train_samples_per_second': 2.072, 'train_steps_per_second': 0.345, 'train_loss': 0.4198189477125804, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/79 [00:00<?, ?it/s]c:\\Users\\Martin\\Desktop\\projects\\master thesis\\master_thesis\\Lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "100%|██████████| 79/79 [00:02<00:00, 34.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1     0.7333    0.9565    0.8302        23\n",
            "           0     0.8125    0.4483    0.5778        29\n",
            "           1     0.7576    0.9259    0.8333        27\n",
            "\n",
            "    accuracy                         0.7595        79\n",
            "   macro avg     0.7678    0.7769    0.7471        79\n",
            "weighted avg     0.7707    0.7595    0.7386        79\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6d5f29de064457bfb8b592578ff569",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "default_single_seed = 77\n",
        "few_shot_samples = 12\n",
        "stratified_seeds = [55, 66, 77, 88, 99]\n",
        "int2str = {-1: 'negative', 0: 'neutral', 1: 'positive'}\n",
        "str2int = {v:k for k, v in int2str.items()}\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [generate_sample(text) for text in examples['text']]\n",
        "    model_inputs = tokenizer(inputs, max_length=512,  truncation=True)\n",
        "\n",
        "    # The labels are tokenized outputs\n",
        "    labels = tokenizer(text_target=examples['label'],\n",
        "                        max_length=512,\n",
        "                        truncation=True)\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "for i in range(5):\n",
        "    train_ds, test_ds = load_data(\"data/train_data.csv\",\n",
        "                                  \"data/test_data.csv\",\n",
        "                                  few_shot_samples,\n",
        "                                  tokenizer,\n",
        "                                  512,\n",
        "                                  model_name,\n",
        "                                  stratified_seeds[i])\n",
        "    \n",
        "    tokenized_train_dataset = train_ds.map(preprocess_function, batched=True)\n",
        "    tokenized_test_dataset = test_ds.map(preprocess_function, batched=True)\n",
        "    tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text', 'label'])\n",
        "    tokenized_test_dataset = tokenized_test_dataset.remove_columns(['text', 'label'])\n",
        "    \n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        weight_decay=0.01,\n",
        "        num_train_epochs=3,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        logging_strategy = 'epoch',\n",
        "        save_strategy=\"epoch\",\n",
        "        predict_with_generate=True,\n",
        "        push_to_hub=False,\n",
        "        load_best_model_at_end=True)\n",
        "    \n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator)\n",
        "    \n",
        "    trainer.train()\n",
        "\n",
        "    golden_labels, predicted_labels = run_on_test(test_ds, model, str2int)\n",
        "    print(classification_report(golden_labels, predicted_labels, digits=4))\n",
        "    \n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0baad91600c14d459e43128baf3416d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4065478bcfb048789b03f9c18f954bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2a5329eab7e4aba93121f2976e09d2f",
              "IPY_MODEL_bdb42c36e19a4ea0ba351c0086cd402d",
              "IPY_MODEL_53900bf72e4a4355bc8c0f059a150ba5"
            ],
            "layout": "IPY_MODEL_8b77789ca5d44737a2b02b33959db4dd"
          }
        },
        "53900bf72e4a4355bc8c0f059a150ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0baad91600c14d459e43128baf3416d5",
            "placeholder": "​",
            "style": "IPY_MODEL_5de78e7e1870452ebda57efc5781b82a",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 422kB/s]"
          }
        },
        "5de78e7e1870452ebda57efc5781b82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769d10133b554148885d04a4de3a94ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b77789ca5d44737a2b02b33959db4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a5329eab7e4aba93121f2976e09d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9cce1679a7f41e5b99985cf15a51c34",
            "placeholder": "​",
            "style": "IPY_MODEL_ebc20f5bf7bf49339ec8197aa1007bf1",
            "value": "Downloading builder script: 100%"
          }
        },
        "b9cce1679a7f41e5b99985cf15a51c34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb42c36e19a4ea0ba351c0086cd402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769d10133b554148885d04a4de3a94ca",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c161b9a219e940fba876d4c3b782a344",
            "value": 6270
          }
        },
        "c161b9a219e940fba876d4c3b782a344": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc20f5bf7bf49339ec8197aa1007bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
